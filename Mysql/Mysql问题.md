#MYSQL 问题
###mysql插入性能分析
插入行所需的时间由以下因素决定（参考MySQL 5.7参考手册：8.2.4.1优化INSERT语句）

- 连接：30%
- 向服务器发送查询：20%
- 解析查询：20%
- 插入行：10% * 行的大小
- 插入索引：10% * 索引数
- 结束：10%

大部分时间耗费在客户端与服务端通信的时间，因此可以使用 insert 包含多个值来减少客户端和服务器之间的通信。

**加快mysql大量数据插入方法**

1. 一次插入多行的值；
2. 关闭自动提交，多次插入数据的 SQL 一次提交；
3. 调整参数，innodb_flush_log_at_trx_commit 和 sync_binlog 都设置为0（当然这种情况可能会丢数据）

###order by排序

order by两种排序方式：

- 有序索引
	- 效率最高
- filesort排序
	- 物理上分为两种种实现方式,自动采用哪种取决于排序的数据大小和`sort_buffer_size`配置的大小
		- “排序的数据大小” < `sort_buffer_size`: 内存排序
		- “排序的数据大小” > `sort_buffer_size`: 磁盘排序
	- 算法上分为三种
		- `< sort_key, rowid >`
			- 双路排序：根据sql语句取出要查询的字段和id，在sort buffer排好序后再去数据库取出行所有字段
			> 1. 从索引 a 找到第一个满足 a = 1000 的主键 id
			> 2. 根据主键 id 取出整行，把排序字段 d 和主键 id 这两个字段放到 sort buffer 中
			> 3. 从索引 a 取下一个满足 a = 1000 记录的主键 id
			> 4. 重复 3、4 直到不满足 a = 1000
			> 5. 对 sort_buffer 中的字段 d 和主键 id 按照字段 d 进行排序
			> 6. 遍历排序好的 id 和字段 d，按照 id 的值回到原表中取出 a、c、d 三个字段的值返回给客户端
		- `< sort_key, additional_fields >`
			- 单路排序：直接取出对应行所有字段在sort buffer进行排序
			> 1. 从索引 a 找到第一个满足 a = 1000 条件的主键 id
			> 2. 根据主键 id 取出整行，取出 a、c、d 三个字段的值，存入 sort_buffer 中
			> 3. 从索引 a 找到下一个满足 a = 1000 条件的主键 id
			> 4. 重复步骤 2、3 直到不满足 a = 1000
			> 5. 对 sort_buffer 中的数据按照字段 d 进行排序
			> 6. 返回结果给客户端
		- `< sort_key, packed_additional_fields >`
			- 类似单路排序，只是char和varchar在sort buffer中排序前进行压缩
		- MySQL 通过比较系统变量 `max_length_for_sort_data` 的大小和需要查询的字段总大小来判断使用哪种排序模式。
			- 如果 `max_length_for_sort_data` 比查询字段的总长度大，那么使用 `< sort_key, additional_fields >`排序模式；
			- 如果 `max_length_for_sort_data` 比查询字段的总长度小，那么使用 `<sort_key, rowid>` 排序模式。
		- 单路排序会把所有需要查询的字段都放到 sort buffer 中，而双路排序只会把主键和需要排序的字段放到 sort buffer 中进行排序，然后再通过主键回到原表查询需要的字段。

####order by 优化
1. 添加索引
	- 可以在排序字段上添加索引来优化排序语句。
	- 如果多个字段排序，可以在多个排序字段上添加联合索引来优化排序语句。
	- 先等值查询再排序的语句，可以通过在条件字段和排序字段添加联合索引来优化此类排序语句。
2. 去掉不必要的返回字段
	- 查询所有字段不走索引的原因是：扫描整个索引并查找到没索引的行的成本比扫描全表的成本更高，所以优化器放弃使用索引。
3. 修改参数
	- `max_length_for_sort_data`：如果觉得排序效率比较低，可以适当加大`max_length_for_sort_data` 的值，让优化器优先选择全字段排序。当然不能设置过大，可能会导致 CPU 利用率过低或者磁盘 I/O 过高；
	- `sort_buffer_size`：适当加大 `sort_buffer_size` 的值，尽可能让排序在内存中完成。但不能设置过大，可能导致数据库服务器 SWAP。
4. 避免无法走索引的情况：
	- 使用范围查询再排序`explain select id,a,b from t1 where a>9000 order by b;`
		> 联合索引中前面的字段使用了范围查询，对后面的字段排序使用不了索引排序。a、b 两个字段的联合索引，对于单个 a 的值，b 是有序的。而对于 a 字段的范围查询，也就是 a 字段会有多个值，取到 a，b 的值 b 就不一定有序了，因此要额外进行排序。
	- ASC 和 DESC 混合使用将无法使用索引

group by语句默认情况，会对 group by 字段排序，因此优化方式与 order by 基本一致，如果目的只是分组而不用排序，可以指定 order by null 禁止排序。

###分页查询
`select a,b,c from t1 limit 10000,10;`

表示从表 t1 中取出从 10001 行开始的 10 行记录。看似只查询了 10 条记录，实际这条 SQL 是先读取 10010 条记录，然后抛弃前 10000 条记录，然后读到后面 10 条想要的数据。因此要查询一张大表比较靠后的数据，执行效率是非常低的。

分页查询两种情形：

1. 根据自增且连续主键排序的分页查询
	- 原始
		- `select * from t1 limit 99000,2;`
		- 表示查询从第 99001开始的两行数据，没添加单独 order by，表示通过主键排序。
	- 改进:
		- `select * from t1 where id >99000 limit 2;`
		- 改进后走主键索引
		- ![avatar](pic/分页查询连续主键优化结果对比图.jpg)</br>
		- 对于主键不连续的情况下不适用，表中可能某些记录被删后，主键空缺，导致结果不一致
		- ![avatar](pic/分页查询连续主键优化错误图.jpg)</br>
2. 查询根据非主键字段排序的分页查询
	- 原始
		- `select * from t1 order by a limit 99000,2;`
		- 原因：扫描整个索引并查找到没索引的行的成本比扫描全表的成本更高，所以优化器放弃使用索引。
	- 优化
		- 让排序时返回的字段尽可能少
		- `select * from t1 f inner join (select id from t1 order by a limit 99000,2)g on f.id = g.id;`
		- ![avatar](pic/非主键字段排序优化结果对比图.jpg)</br>

###join 表
join关联查询主要分为三种算法,mysql会自动选择小表作为驱动表：
1. Nested-Loop Join
	- 每次从驱动表中取出一行，用这行的关联数据去被驱动表中查找
	- 仅当被驱动表中有关联数据的索引时才使用此算法，不然此算法查找次数为n*m（驱动和被驱动表行数分别为n和m）
2. Block Nested-Loop Join
	- 先把驱动表数据读入`join_buffer`，然后对被驱动表进行逐行扫描与`join_buffer`中的数据作对比
	- 表查找次数为n+m,计算次数为n*m，所以当被驱动表没有建立索引时此方式查找次数少很多
3. Batched Key Access
	- 将驱动表中相关列放入 join_buffer 中
	- 批量将关联字段的值发送到 Multi-Range Read(MRR) 接口
	- MRR 通过接收到的值，根据其对应的主键 ID 进行排序，然后再进行数据的读取和操作

优化：
	- 在被驱动表的关联字段上添加索引;让 BNL变成 NLJ 或者 BKA ，可明显优化关联查询。
	- 小表做驱动表;小表驱动大表（默认）
	- 临时表;当遇到 BNL 的 join 语句，如果不方便在关联字段上添加索引，不妨尝试创建临时表，然后在临时表中的关联字段上添加索引，然后通过临时表来做关联查询。

###count()函数
count(a)和count()相比前者不会计算a=null的行，后者会返回所有行记录。

InnoDB中不会记录表中的行数，因为并发事务可能导致同事读取到不同的行数

mysql5.7后通过遍历最小的可用二级索引来处理count()语句，如果不存在二级索引，则扫描聚簇索引。原因是 InnoDB 二级索引树的叶子节点上存放的是主键，而主键索引树的叶子节点上存放的是整行数据，所以二级索引树比主键索引树小。因此优化器基于成本的考虑，优先选择的是二级索引。所以 count(主键) 其实没 count (*) 快。

几种优化 count() 的方式：
	- show table status：能快速获取结果，但是结果不准确；
	- 用 Redis 做计数器：能快速获取结果，比 show table status 结果准确，但是并发场景计数可能不准确；
	- 增加 InnoDB 计数表：能快速获取结果，利用了事务特性确保了计数的准确，也是比较推荐的方法。

##索引
没使用索引的原因：

1. 建立组合索引，但查询谓词并未使用组合索引的第一列，此处有一个INDEX SKIP SCAN概念。
2. 在包含有null值的table列上建立索引，当时使用select count(*) from table时不会使用索引。
3. 在索引列上使用函数时不会使用索引（包括类型转换），如果一定要使用索引只能建立函数索引。
	> 索引树中存储的是列的实际值和主键值。如果拿 ‘表达式内的值’ 去匹配，将无法定位到索引树中的值。因此放弃走索引，而选择全表扫描。
4. 并不是所有情况使用索引都会加快查询速度，full scan table 有时会更快，尤其是当查询的数据量占整个表的比重较大时，因为full scan table采用的是多块读
5. 如果条件中有or，即使其中有条件带索引也不会使用。换言之，就是要求使用的所有字段，都必须建立索引，我们建议大家尽量避免使用or 关键字 
6. 模糊查询条件
	> 通配符在最前面不使用索引如`select * from t1 where a like '%1111%';`</br>
	> 修改后则走索引`select * from t1 where a like '1111%';`</br>
	> 如果条件只知道中间的值，需要模糊查询去查，那就建议使用ElasticSearch或其它搜索服务器。
7. 范围查询中条件范围过大
	> 优化器会根据检索比例、表大小、I/O块大小等进行评估是否使用索引。比如单次查询的数据量过大，优化器将不走索引,可以将一次大范围查询分为多次小范围查询
8. 计算操作
	> 对索引字段做运算将使用不了索引。</br>
	> `explain select * from t1 where b-1 =1000;`</br>
	> 可以将计算操作放在等号后面</br>
	> `explain select * from t1 where b =1000 + 1;`

![avatar](pic/B树查询结构图.jpg)</br>

###需要添加索引的情况
1. 数据查询检索
	- `select * from t9_1 where d = 90000;`
2. 聚合函数
	- `select max(d) from t9_1;`
3. 排序
	- 如果对单个字段排序，则可以在这个排序字段上添加索引来优化排序语句；
	- 如果是多个字段排序，可以在多个排序字段上添加联合索引来优化排序语句；
	- 如果是先等值查询再排序，可以通过在条件字段和排序字段添加联合索引来优化排序语句。
4. 避免回表
	- 通过辅助索引来寻找数据，InnoDB 存储引擎会遍历辅助索引树查找到对应记录的主键，然后通过主键索引回表去找对应的行数据。
	- 条件字段和需要查询的字段有联合索引的话，其实回表这一步就省了，因为联合索引中包含了这两个字段的值。像这种索引就已经覆盖了我们的查询需求的场景，我们称为：覆盖索引
5. 关联查询
	- 过在关联字段添加索引，让 BNL变成 NLJ 或者 BKA。

##锁
###全局锁和表锁什么场景下会用到
####全局锁
MySQL 全局锁会关闭所有打开的表，并使用全局读锁锁定所有表,当执行 FTWRL 后，所有的表都变成只读状态，数据更新或者字段更新将会被阻塞
> `FLUSH TABLES WITH READ LOCK`</br>
> 简称`FTWRL`</br>
> 解锁`UNLOCK TABLES`

全局锁一般用在整个库（包含非事务引擎表）做备份（mysqldump 或者 xtrabackup）时。也就是说，在整个备份过程中，整个库都是只读的，其实这样风险挺大的。如果是在主库备份，会导致业务不能修改数据；而如果是在从库备份，就会导致主从延迟。

好在 mysqldump 包含一个参数 --single-transaction，可以在一个事务中创建一致性快照，然后进行所有表的备份。因此增加这个参数的情况下，备份期间可以进行数据修改。但是需要所有表都是事务引擎表。所以这也是建议使用 InnoDB 存储引擎的原因之一。

而对于 xtrabackup，可以分开备份 InnoDB 和 MyISAM，或者不执行 --master-data，可以避免使用全局锁。
####表锁
表锁分为表锁和元数据锁两种

使用场景：

- 事务需要更新某张大表的大部分或全部数据。如果使用默认的行锁，不仅事务执行效率低，而且可能造成其它事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高事务执行速度；
- 事务涉及多个表，比较复杂，可能会引起死锁，导致大量事务回滚，可以考虑表锁避免死锁。
其中表锁又分为表读锁和表写锁，命令分别是：

表锁分为两种：

- 表读锁：
	> 对表执行 lock tables xxx read （表读锁）时，本线程和其它线程可以读，本线程写会报错，其它线程写会等待
- 表写锁：
	> 对表执行 lock tables xxx write （表写锁）时，本线程可以读写，其它线程读写都会阻塞

元数据锁：
> 在 MySQL 中，DDL 是不属于事务范畴的。如果事务和 DDL 并行执行同一张表时，可能会出现事务特性被破坏、binlog 顺序错乱等 bug,由此引入了引入了元数据锁（Metadata Locking，简称：MDL 锁）</br>
> MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。


虽然 MDL 锁是系统默认加的，但是却不能忽略一个机制，比如下面一个例子：可能会给一个小表加字段，导致整个库都挂了。

你肯定知道，给一个表加字段、或者修改字段、或者加索引，需要扫描全表的数据。对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出现问题。

比如sessionA、sessionB、sessionC、sessionD 依次执行，一个 sessionA 先启动，这个时候会对表 t 加一个 MDL 读锁，由于 sessionB 需要的也是 MDL 读锁，读锁之间不互斥，因此可以正常执行。之后 sessionC 会被阻塞，因为事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而是等到事务提交之后再释放。所以 sessionA 读锁还没有释放而 sessionC需要一个写锁，因此只能被阻塞。

如果说 sessionC 自己阻塞了没有关系，但是之后所有要在表 t 上心申请 MDL 读锁的请求也会被 sessionC 阻塞，就等于这个表完全不可读写了。如果某个表上的查询语句频繁，而且客户端有重试机制，超时之后再重启一个 session，这个库的线程很快就会爆满。

基于上面的分析，我们来讨论一个问题，如何安全地给小表加字段 ？

首先要解决长事务，事务不提交，就会一直占着 MDL 锁， 在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查看当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。

但考虑一下这个场景，如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，你不得不加字段，你该怎么做呢？这个时候 kill 可能也未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里设定等待时间，如果在这个指定时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃，之后开发人员或者 DBA 再通过重试命令重复这个过程。

###行锁：InnoDB 替代 MyISAM 的重要原因

早起关系型数据库采用两段锁模式：加锁->解锁，执行语句加锁，事务结束解锁，语句执行完并不立即解锁。

1. 通过非索引字段查询
	> 在 MySQL 中，如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由 server 层进行过滤。因此也就把所有记录都锁上了。当然 MySQL 在这里有一些改进的，在 server 层过滤掉不满足条件的数据后，会把不满足条件的记录放锁。保证了最后只会持有满足条件的锁，但是每条记录的加锁操作还是不会省略。
	
	> 没有索引的情况下，InnoDB 的当前读会对所有记录都加锁。所以在工作中应该特别注意 InnoDB 这一特性，否则可能会产生大量的锁冲突。
	> 
	> 在更新数据时，如果条件字段没索引，则表中所有记录都会被加上 X 锁

2. 通过非唯一索引查询
	> 如果查询的条件是唯一索引，那么 SQL 需要在满足条件的唯一索引上加锁，并且会在对应的聚簇索引上加锁。
3. 通过非唯一索引查询
	> 如果查询的条件是非唯一索引，那么 SQL 需要在满足条件的非唯一索引上都加上锁，并且会在它们对应的聚簇索引上加锁。

###间隙锁意义

间隙锁定是锁定索引记录之间的间隙，或者锁定第一个和最后一个记录之间的间隙。组织其他事务将值插入到这个间隙中来，间隙可能跨越单个索引值，多个索引值，也有可能为空。

**可重复读（RR）级别下才会有间隙锁！！！！**

间隙锁定之间不存在冲突关系，这点也很重要。如果一个事务对某个间隙中间加了锁，那么其他事务也可以在这个间隙中加锁，这些操作不冲突。他的存在，仅仅是为了防止其他事务在这个间隙中插入记录。

- 间隙锁锁定的是某个索引记录之前和之后的一个间隙范围。
- 间隙锁之间互不影响，可以在锁定的区间再次添加间隙锁。
- 间隙锁可能造成死锁

当字段是唯一索引或者主键的时候，间隙锁产生的规则如下：

- 如果查询的结果中包含这个记录，那么在另外的会话上插入该记录前后间隙的记录时，不会产生间隙锁
- 如果查询的结果中不包含这个记录，那么在另外的会话上插入该记录前后间隙的记录时，会产生间隙锁。

##Mysql查询过程
![avatar](pic/mysql查询流程结构图.png)</br>
![avatar](pic/mysql查询流程图.png)</br>


###客户端/服务端通信协议
MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。

客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。

与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。

###查询缓存

在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。

MySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。

如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果都不会被缓存。MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：

- 任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存
- 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗

基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：

- 用多个小表代替一个大表，注意不要过度设计
- 批量插入代替循环单条插入
- 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适
- 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存

最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。

[[玩转MySQL之四]MySQL缓存机制](https://zhuanlan.zhihu.com/p/55947158)

###日志
MySQL日志分类:

- 错误日志
    > 记录信息：
    >   - 服务器启动和关闭过程中的信息</br>
    >   - 服务器运行过程中的错误信息
    >   - 事件调度器运行一个事件时产生的信息
    >   - 在从服务器上启动从服务器进程时产生的信息
    >       - 在复制环境下，从服务器进程的信息也会被记录进错误日志</br>
    > 
    > 默认开启，无法被禁止。存储在数据库的数据文件目录中，名称为hostname.err，其中，hostname为服务器主机名。
- 查询日志(通用日志)
    > 查询日志里面记录了数据库执行的所有命令，不管语句是否正确，都会被记录，会导致IO非常大，影响MySQL性能,因此如果不是在调试环境下，是不建议开启查询日志功能的。</br>
    >
    > 查询日志的开启有助于帮助我们分析哪些语句执行密集，执行密集的select语句对应的数据是否能够被缓存，同时也可以帮助我们分析问题
- 慢查询日志
    >  开启慢查询日志，可以让MySQL记录下查询超过指定时间的语句，能够很好的优化数据库性能。默认情况下不开启.
- 事务日志(Redo log)
    > innodb通过force log at commit机制实现事务的持久性，即在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化。
    >
    > 分为：
    > 
    > - 重做日志redo
    >     - redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的，并且是事务的记录是顺序追加的，性能非常高.为了确保每次日志都能写入到事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作(即fsync()系统调用)。
    >     - MySQL通过变量 `innodb_flush_log_at_trx_commit` 的值来自定义在commit时如何将log buffer中的日志刷log file中。该变量有3种值：0、1、2，默认为1。但注意，这个变量只是控制commit动作是否刷新log buffer到磁盘。
    >       - 当设置为0的时候，事务提交时不会将log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到log file on disk中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。
    >       - 当设置为1的时候，事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷到log file on disk中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。
    >       - 当设置为2的时候，每次提交都仅写入到os buffer，然后是每秒调用fsync()将os buffer中的日志写入到log file on disk。
    >     - 在主从复制结构中，要保证事务的持久性和一致性，下述两项变量的设置保证了：每次提交事务都写入二进制日志和事务日志，并在提交时将它们刷新到磁盘中。
    >       - 如果启用了二进制日志，则设置sync_binlog=1，即每提交一次事务同步写到磁盘中
    >       - 总是设置`innodb_flush_log_at_trx_commit=1`，即每提交一次事务都写到磁盘中
    > - 回滚日志undo
    >     - undo log有两个作用：提供回滚和多个行版本控制(MVCC)。undo log默认存放在共享表空间中。
    >       - 提供回滚
    >          - 在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。
    >       - 多个行版本控制(MVCC)
    >          - 应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。
- 二进制日志(binlog)
	> 一个二进制文件，主要记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的所有操作。二进制日志（binary log）中记录了对MySQL数据库执行更改的所有操作，并且记录了语句发生时间、执行时长、操作数据等其它额外信息，但是它不记录SELECT、SHOW等那些不修改数据的SQL语句。
	> 
	> - 作用：
	>    - 恢复（recovery）：某些数据的恢复需要二进制日志。例如，在一个数据库全备文件恢复后，用户可以通过二进制日志进行point-in-time的恢复。
	>    - 复制（replication）：其原理与恢复类似，通过复制和执行二进制日志使一台远程的MySQL数据库（一般称为slave或者standby）与一台MySQL数据库（一般称为master或者primary）进行实时同步。
	>    - 审计（audit）：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击。
	>    - 崩溃保持一致性：在开启binlog的情况下，为了保证binlog与redo的一致性，MySQL将采用事务的两阶段提交协议。当MySQL系统发生崩溃时，事务在存储引擎内部的状态可能为prepared和commit两种。对于prepared状态的事务，是进行提交操作还是进行回滚操作，这时需要参考binlog：如果事务在binlog中存在，那么将其提交；如果不在binlog中存在，那么将其回滚，这样就保证了数据在主库和从库之间的一致性。
	> - 记录格式：
	>    - STATEMENT
	>       - 记录的是数据库上执行的原生SQL语句，好处就是相当简单，简单地记录和执行这些语句，能够让主备保持同步，在主服务器上执行的SQL语句，在从服务器上执行同样的语句。另一个好处是二进制日志里的时间更加紧凑，所以相对而言，基于语句的复制模式不会使用太多带宽，同时也节约磁盘空间。并且通过mysqlbinlog工具容易读懂其中的内容。
	>       - 坏处就是同一条SQL在主库和从库上执行的时间可能稍微或很大不相同，因此在传输的二进制日志中，除了查询语句，还包括了一些元数据信息，如当前的时间戳。即便如此，还存在着一些无法被正确复制的SQL。存储过程和触发器在使用基于语句的复制模式时也可能存在问题。另外一个问题就是基于语句的复制必须是串行化的。这要求大量特殊的代码，配置，例如InnoDB的next-key锁等。并不是所有的存储引擎都支持基于语句的复制。
	>    - ROW
	>       - 基于数据的复制，基于行的更改。这种方式会将实际数据记录在二进制日志中，它有其自身的一些优点和缺点，最大的好处是可以正确地复制每一行数据。一些语句可以被更加有效地复制，另外就是几乎没有基于行的复制模式无法处理的场景，对于所有的SQL构造、触发器、存储过程等都能正确执行。
	>       - 主要的缺点就是二进制日志可能会很大，而且不直观，所以，你不能使用mysqlbinlog来查看二进制日志。也无法通过看二进制日志判断当前执行到那一条SQL语句了。
	>    - MIXED
	>       - MIXED也是MySQL默认使用的二进制日志记录方式，但MIXED格式默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。比如用到UUID()、USER()、CURRENT_USER()、ROW_COUNT()等无法确定的函数。


- 中继日志
	> relay log是复制过程中产生的日志，很多方面都跟binary log差不多，区别是: relay log是从库服务器I/O线程将主库服务器的二进制日志读取过来记录到从库服务器本地文件，然后从库的SQL线程会读取relay-log日志的内容并应用到从库服务器上。

[玩儿转MYSQL之日志分类及简介](https://zhuanlan.zhihu.com/p/58011817)

###mysql数据库恢复过程
![avatar](pic/数据库恢复流程图.jpg)</br>

1. 准备工作
	- 查看是否开启binlog二进制日志和数据库是否有备份。
2. 利用数据库备份还原数据表结构
3. 查看binlog日志列表，找到备份最后修改时间戳的对应日志文件
	- `show master logs；`
4. 备份导出日志文件
	- `mysqlbinlog mysql-bin.000011 > bak.log`
5. 根据删除命令时间导出需要执行的日志
	- `mysqlbinlog --stop-datetime="2019-09-07 17:30:31" mysql-bin.000011 >all.sql`