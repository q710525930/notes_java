# Redis面试题

## 数据结构与类型

- Redis有哪几种数据类型和结构？给你一个 key 怎么知道是用的哪种结构？

  - 类型：
    - String
    - Map
    - list
    - set
    - sortset：有序Set。内部维护了一个`score`的参数来实现。适用于排行榜和带权重的消息队列等场景。
    - bitmap: 位图，可做布隆过滤器
    - Hyperloglog:  做基数统计的[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)，其优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。典型的使用场景是统计独立访客。
    - Geospatial: 位置坐标，适用于定位

- Zset底层数据结构？适用场景？

- string的底层优化？list的使用场景？

- keys命令存在什么问题？

  - keys命令会阻塞redis服务直到完成，scan采用渐进式复杂度O1，但是可能扫描出来键信息不及时

- redis为什么用hash槽不用hash环？

  - <details>
      <summary>答案</summary>
      为了防止redis这种热点数据大量堆积到一个点，当一个节点崩溃时大量数据转移到下一个节点依次崩溃，类似多米诺。hash环结构更多适用于分部平均且节点较多的场景
    </details>

## 持久化

- AOF与RDB区别

  - <details>
      <summary>答案</summary>
    RDB优点
    	RDB是一个二进制文件，代表Redis在某一个时间点上的数据快照，非常适合用于备份、全量复制等场景。
    	RDB对灾难恢复、数据迁移非常友好，RDB文件可以转移至任何需要的地方并重新加载。
    	RDB是Redis数据的内存快照，数据恢复速度较快，相比于AOF的命令重放有着更高的性能。
    RDB缺点
    	RDB方式无法做到实时或秒级持久化。因为持久化过程是通过fork子进程后由子进程完成的，子进程的内存只是在fork操作那一时刻父进程的数据快照，而fork操作后父进程持续对外服务，内部数据时刻变更，子进程的数据不再更新，两者始终存在差异，所以无法做到实时性。
    	RDB持久化过程中的fork操作，会导致内存占用加倍，而且父进程数据越多，fork过程越长。
    	Redis请求高并发可能会频繁命中save规则，导致fork操作及持久化备份的频率不可控；
    	RDB文件有文件格式要求，不同版本的Redis会对文件格式进行调整，存在老版本无法兼容新版本的问题。
    AOF优点
    	AOF持久化有更好的实时性，我们可以选择三种不同的方式（appendfsync）：no、every second、always，every second作为默认的策略具有最好的性能，极端情况下可能会丢失一秒的数据。
    AOF文件只有append操作，无复杂的seek等文件操作，没有损坏风险。即使最后写入数据被截断，也很容易使用redis-check-aof工具修复；
    	当AOF文件变大时，Redis可在后台自动重写。重写过程中旧文件会持续写入，重写完成后新文件将变得更小，并且重写过程中的增量命令也会append到新文件。
    	AOF文件以已于理解与解析的方式包含了对Redis中数据的所有操作命令。即使不小心错误的清除了所有数据，只要没有对AOF文件重写，我们就可以通过移除最后一条命令找回所有数据。
    	AOF已经支持混合持久化，文件大小可以有效控制，并提高了数据加载时的效率。
    AOF缺点
    	对于相同的数据集合，AOF文件通常会比RDB文件大；
    	在特定的fsync策略下，AOF会比RDB略慢。一般来讲，fsync_every_second的性能仍然很高，fsync_no的性能与RDB相当。但是在巨大的写压力下，RDB更能提供最大的低延时保障。
    	在AOF上，Redis曾经遇到一些几乎不可能在RDB上遇到的罕见bug。一些特殊的指令（如BRPOPLPUSH）导致重新加载的数据与持久化之前不一致，Redis官方曾经在相同的条件下进行测试，但是无法复现问题。
    </details>

- RDB写入底层逻辑

- 一台机器8G Redis配置6G 采取rdb模式 读写请求比例为2比8 问会有什么问题？

  - <details>
      <summary>答案</summary>
    Linux fork 子进程采用的是 copy-on-write 的方式。在 Redis 执行 RDB 持久化期间，如果 client 写入数据很频繁，那么将增加 Redis 占用的内存，最坏情况下，内存的占用将达到原先的2倍。刚 fork 时，主进程和子进程共享内存，但是随着主进程需要处理写操作，主进程需要将修改的页面拷贝一份出来，然后进行修改。极端情况下，如果所有的页面都被修改，则此时的内存占用是原先的2倍。
    </details>

## 集群

- 扩容时  新老旧节点 数据迁移具体是怎么做的？

- 集群为什么是16384，哨兵模式，选举过程，会有脑裂问题么

  - <details>
    	<summary>答案</summary>
      https://www.cnblogs.com/youngdeng/p/12855424.html?ivk_sa=1024320u
      简单总结，就是因为集群之间每s要互发PING/PONG交换消息，消息体重会携带myslot槽数据，格式为bitmap，每一位代表一个槽，如果该位为1，表示这个槽是属于这个节点的。16384÷8÷1024=2kb。在消息体中，会携带一定数量的其他节点信息用于交换。约为集群总节点数量的1/10，至少携带3个节点的信息，所以节点数量越多，消息体内容越大。
      如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大，浪费带宽。redis的集群主节点数量基本不可能超过1000个，所以16438完全够用。槽位越小，节点少的情况下，传输过程中bitmap压缩比高
    </details>

- 集群的不足

  - <details>
      <summary>答案</summary>
      假设我有一个key，对应的value是Hash类型的。如果Hash对象非常大，是不支持映射到不同节点的！只能映射到集群中的一个节点上！还有就是做批量操作比较麻烦！
      批量操作也就是mset、mget等，集群不同的key会划分到不同的slot中，因此直接使用mset或者mget等操作是行不通的(应对方法:如果执行的key数量比较少，就不用mget了，就用串行get操作。如果真的需要执行的key很多，就使用Hashtag保证这些key映射到同一台redis节点上,语法：对于key为{foo}.student1、{foo}.student2，{foo}student3，这类key一定是在同一个redis节点上。因为key中“{}”之间的字符串就是当前key的hash tags， 只有key中{ }中的部分才被用来做hash，因此计算出来的redis节点一定是同一个!)
    </details>
  
- 哨兵模式工作原理

  - sentinel每秒发送ping到master，如果未收到回复单个sentinel判断主观下线，其他在监视的sentinel都要进行主观下线判断，达到阈值则判定下线；哨兵节点推举出哨兵leader进行节点替换。
  

## 键值特性

- Redis的主键争用问题如何解决？（如扣减库存，多个请求都要去扣库存）

  - 乐观锁，watch命令可实现，注意不要在分片集群中使用
  - 分布式锁，适合分布式系统环境
    - 基于zoo[keep]()er临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zoo[keep]()er上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。

  - 时间戳，适合有序场景，写入时保存一个时间戳，写入前先比较早于现有记录的时间戳就不写入
  - 消息队列，串行化处理

- Redis淘汰和过期策略？如果没有数据可以淘汰或者没有配置淘汰策略读请求可以正常执行吗？

  - <details>
      <summary>答案</summary>
      通过配置redis.conf中的maxmemory这个值来开启内存淘汰功能
      键存储在Redis中，有一个哈希表用于存储这批键及其值，如果这批键中有一部分设置了过期时间，那么这批键还会被存储到另外一个哈希表中，这个哈希表中的值对应的是键被设置的过期时间，实际上会消耗更多的内存，因此建议使用allkeys-lru策略有效率的使用内存。
      - 淘汰策略
      	- allkeys lru: 淘汰最长时间没使用的key
      	- allkeys random: 所有key随机删除
      	- allkeys lfu: 淘汰使用频率的key
      	- volatile lru
      	- volatile random
      	- volatile lfu
      	- volatile ttl：从配置了过期时间的键中驱逐马上就要过期的键
      - 过期策略
      	- 定期删除: 定期遍历设置了过期时间的哈希表，删除到期key，默认10/s，遍历采用贪心策略（随机选择20个key，如果20个中过期比例大于1/4，则重复执行，减少遍历大量key带来的cpu负载）
      	- 惰性删除: 访问指定key时进行过期检查，过期则立即删除且不会返回
      	- 定时删除: 创建过期时间时设置定时器，到时间立即删除
      不管是定期删除还是惰性删除都会存在key没有被删除掉的场景，所以就需要内存淘汰策略进行补充。
      其中lru方式也是同定期删除一样，随机选取N个数再对其进行lru算法删除。lfu计数counter也并不是采取线性增加的计算方式，且新key的初始化counter默认为5可以预防被轻易淘汰。
    </details>

- redis 内存优化？

  - <details><summary>答案</summary>
    	- Redis内部会构建一个数字池，默认是10000。Redis中如果存储的是“123”，Redis是能够识别出来这是一个数字并且按照数字来存储，节省存储空间，且直接存储数字池里面对应的索引就行
      - 复杂类型的存储优化，比如Map，List，Set等，这些集合都有一个特点可大可小
    </details>

## 性能

- Redis为什么快

  - <details>
    <summary>答案</summary>
    1. 基于内存：Redis是使用内存存储，没有磁盘IO上的开销。数据存在内存中，读写速度快。
    2. 单线程实现（ Redis 6.0以前）：Redis使用单个线程处理请求，避免了多个线程之间线程切换和锁资源争用的开销。单线程是指网络请求使用一个线程来处理，即一个线程处理所有网络请求，Redis 运行时不止有一个线程，比如数据持久化的过程会另起线程。
    3. IO多路复用模型：Redis 采用 IO 多路复用技术。Redis 使用单线程来轮询描述符，将数据库的操作都转换成了事件，不在网络I/O上浪费过多的时间。
    4. 高效的数据结构：Redis 每种数据类型底层都做了优化，目的就是为了追求更快的速度。
    </details>

- 什么是IO多路复用？select、poll、epoll区别？

  - <details>
    <summary>答案</summary>
    IO多路复用指的是一种同步IO模型，实现一个线程监听多个句柄；句柄就绪则通知线程进行读写，未就绪则阻塞。
    IO分为同步阻塞(BIO)、同步非阻塞(NIO)与IO多路复用：
      BIO: 一个线程aceept任务后等待完成后再释放，过程阻塞。可开多线程并发处理，但是多线程代价较大
      NIO: 一个线程aceept数据后加入fds集合中，然后遍历所有fds集合，如果没有非阻塞任务返回错误
    IO多路复用区别：
      select: 轮训所有fd中的流，缺点：单个线程维护fd大小有限，默认1024，每次调用会把fd从用户态拷贝到内核态开销大；线性轮训所有socket耗时长。
      poll: 与select区别仅仅只是用链表存储fd，fd没有大小限制
      epoll: 就绪的socket会自动回调然后加入就绪双向链表，只用扫描就绪链表即可，只可工作在linux下。使用mmap文件映射内存加速与内核空间的消息传递减少复制开销（将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系）
      select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。
      select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。
    	select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。
      https://blog.csdn.net/weixin_39934085/article/details/110715861
    </details>

- redis读写分离？

  - <details>
      <summary>答案</summary>
      不做读写分离。redis本身在内存上操作，不会涉及IO吞吐，即使读写分离也不会提升太多性能，Redis在生产上的主要问题是考虑容量，单机最多10-20G，key太多降低redis性能.因此采用分片集群结构，已经能保证了我们的性能。其次，用上了读写分离后，还要考虑主从一致性，主从延迟等问题，徒增业务复杂度。
    </details>

## 应用

- 分布式锁 排行榜 怎么实现

- 缓存穿透、血崩、击穿？

  - <details>
    <summary>答案</summary>
    穿透：查询redis中没有的key或者非法数据如id=-1，导致大量请求到Db；
      - 非法参数校验；缓存为空的数据；布隆过滤器；
    血崩：大量key同一时间过期，导致大量请求到Db；
      - 分散key失效时间；设置二级缓存；高可用方案；热点数据永不过期，更新数据同时更新缓存
    击穿：单个key过期，对该热点key的大量请求到Db；
      - 分布式锁控制访问，如redis的setnx互斥锁先进行判断，保证不会有大量访问到Db；热点数据永不过期
    </details>

- 缓存预热？缓存降级？

- 什么是redlock？

  - <details>
    <summary>答案</summary>
    基于 Redis 实现分布式锁的方式。此种方式比原先的单节点的方法更安全。保证以下特性： 
    -  安全特性：互斥访问，即永远只有一个 client 能拿到锁； 
    -  避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区； 
    -  容错性：只要大部分 Redis 节点存活就可以正常提供服务；
    过程：
    -  按顺序向5个master节点请求加锁
    -  根据设置的超时时间来判断，是不是要跳过该master节点。
    -  如果大于等于三个节点加锁成功，并且使用的时间小于锁的有效期，即可认定加锁成功啦。
    -  如果获取锁失败，解锁！
    </details>

- redis事务？

  - <details>
      <summary>答案</summary>
      生产上采用的是Redis Cluster集群架构，不同的key是有可能分配在不同的Redis节点上的，在这种情况下Redis的事务机制是不生效的。其次，Redis事务本质就是多命令的打包执行，不支持回滚操作，且不具有原子性，遇到命令语法错误会忽略继续执行，简直是鸡肋！所以基本不用！
    </details>

- redis多数据库？

  - <details>
      <summary>答案</summary>
      单机下可以支持16个数据库（db0 ~ db15）,并且每个数据库的数据是隔离的不能共享，在Redis Cluster集群架构下只有一个数据库，即db0。因此，我们没有使用Redis的多数据库功能！
    </details>

- redis做分布式锁可能出现的问题

  - <details>
      <summary>答案</summary>
      重复加锁，主从或者集群模式下，主从复制过程中刚好主节点挂了导致同步失败（多主机加锁，参考redlock）
      业务执行过长导致锁自动释放（加入看门狗机制解决）
      业务代码忘解锁，看门狗机制生效中，锁无法释放（虚引用监听，保底）Redis 实现分布式锁实际上是通过setnx 命令, 如果有该key值, 则设置失败, 没有该key, 设置成功.
    但是由于setnx 命令没有过期时间的, 需要额外对key设置过期时间, 但是这个是两步操作, 不能保证其原子性.set key value EX seconds NX 语句, 就是保证了原子性, 并且能够达到与setnx一致的效果.
    set key value 传入ex是秒, px 是毫秒 NX 是键不存在时 ,才能设置, 否则返回nil
    </details>

- redis 缓存一致性

  - <details>
    <summary>答案</summary>
    1. 先删缓存，再更新数据库
    先删除缓存，数据库还没有更新成功，此时如果读取缓存，缓存不存在，去数据库中读取到的是旧值，缓存不一致发生。
      解决方案
    延时双删的方案的思路是，为了避免更新数据库的时候，其他线程从缓存中读取不到数据，就在更新完数据库之后，再sleep一段时间，然后再次删除缓存。sleep的时间要对业务读写缓存的时间做出评估，sleep时间大于读写缓存的时间即可。
      延时双删更新数据库后再删除redis也可能删除失败，这时候可以使用消息队列进行重试或者读取mysql的binlog用MQ进行异步删除
    2. 先更新数据库，再删除缓存
    更新数据库成功，如果删除缓存失败或者还没有来得及删除，那么，其他线程从缓存中读取到的就是旧值，还是会发生不一致。
      解决方案
    消息队列,先更新数据库，监听binLog，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。(不用你自己引入，侵入到你的业务代码中，中间件帮你做了解耦，且能支持读写分离场景，因为读写分离用binlog同步)
    为什么是删除而不是更新，因为如果是先更新数据库再更新缓存，那么如果写了1000次只读了1次，也会更新1000次，造成不必要的开销。
      https://blog.csdn.net/v123411739/article/details/114803998
    </details>

